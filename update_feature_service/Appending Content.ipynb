{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c0073d-4318-4085-a9ca-a563c82d7a1a",
   "metadata": {},
   "source": [
    "### Enter Item ID Below of Source and Target Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580e983e-4804-444c-809a-c9caf9923cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Layer details\n",
    "source_item_id = '59ea577aed334362bf7106c6771c82cf'\n",
    "soure_layer_id = 0\n",
    "\n",
    "# Target layer to load data into\n",
    "target_item_id = '59ea577aed334362bf7106c6771c82cf'\n",
    "target_layer_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88582c91-e842-4e49-9d57-31ec39b5beb7",
   "metadata": {},
   "source": [
    "## Logging into your ArcGIS Online Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0240ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c947f42-ac12-403d-8d67-803bf5349df0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Password: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `verify_cert` to False is a security risk, use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in as: foretify_proton\n"
     ]
    }
   ],
   "source": [
    "arcgis_org_url=\"https://foretify.maps.arcgis.com/\"\n",
    "username= \"foretify_proton\"\n",
    "password=getpass.getpass(\"Enter Password: \")\n",
    "gis = GIS(arcgis_org_url, username, password, verify_cert=False)\n",
    "print(\"Successfully logged in as: \" + gis.properties.user.username)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f0d428-582c-45b3-a19e-0bf10375c8f3",
   "metadata": {},
   "source": [
    "## Functions and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95a97d07-8b50-4fe0-ba1c-e832a0e9fdf0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "from configparser import ConfigParser, SafeConfigParser, RawConfigParser\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Dict, Text\n",
    "\n",
    "from arcgis.gis import GIS, Item\n",
    "from arcgis.features import feature, FeatureSet, FeatureCollection, FeatureLayer\n",
    "from arcgis.geometry.filters import intersects\n",
    "from arcgis.geometry import find_transformation, project, SpatialReference\n",
    "\n",
    "\n",
    "def  append_to_layer(source_data, target_layer, gis=None, matching_field=None, upsert_flag=False):\n",
    "    \"\"\"Append a dataframe to a hosted feature layer\n",
    "    \n",
    "    Dataframe is converted to a feature collection and uploaded to users content\n",
    "    in order to be appended to target layer.\n",
    "\n",
    "    After processing, item is deleted.\n",
    "\n",
    "    Args:\n",
    "        source_data ([dataframe]): Source data that will be appended to target layer.\n",
    "        target_layer ([layer]): Target layer that data is appended to\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a temporary name based on GUID ID\n",
    "        temp_name = uuid.uuid4().hex\n",
    "\n",
    "        # convert source data to feature collection and add to organization\n",
    "        fs = FeatureSet.from_dataframe(source_data)\n",
    "        # For cases where just attributes in a target layer are getting updated with no geometry modifications,\n",
    "        # we will need to ensure the geometryType and spatialReference properties match the target layer in order \n",
    "        # to make a feature collection.\n",
    "        if fs.features[0].geometry_type == 'Table':\n",
    "            fs.geometry_type = target_layer.properties.geometryType\n",
    "            fs.spatial_reference = target_layer.properties.extent.spatialReference\n",
    "        feat_collection = FeatureCollection.from_featureset(fs)  \n",
    "        temp_fc_properties = {\n",
    "                            'title': temp_name,\n",
    "                            'description':'Temporary collection of features.',\n",
    "                            'tags': 'arcgis python api, pandas, featureCollection, Temp, Temporary',\n",
    "                            'text': feat_collection._lyr_json,\n",
    "                            'type':'Feature Collection'\n",
    "                            }\n",
    "        temp_fc_layer = gis.content.add(temp_fc_properties)\n",
    "        print(f\"Attempting to append records in {temp_name} on Hosted Feature Layer {target_layer.properties.name}\")\n",
    "\n",
    "        target_layer.append(upload_format='featureCollection',\n",
    "                        item_id=temp_fc_layer.id,\n",
    "                        upsert=upsert_flag,\n",
    "                        skip_updates=False,\n",
    "                        skip_inserts=False,\n",
    "                        update_geometry=False,\n",
    "                        use_globalids=False,\n",
    "                        rollback=False,\n",
    "                        upsert_matching_field=matching_field)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to append on Hosted Feature Layer {target_layer.properties.name}\")\n",
    "        print(e, exc_info=True)\n",
    "    finally:\n",
    "        # Delete temporary item\n",
    "        temp_fc_layer.delete()\n",
    "\n",
    "\n",
    "def append_to_table(source_data, target_table, gis=None, matching_field=None, upsert_flag=False):\n",
    "    \"\"\"Append a dataframe to a hosted table.\n",
    "    \n",
    "    Dataframe is converted to a csv file and saved to the same folder as the log file. File\n",
    "    is then uploaded to users content in order to be appended to target table.\n",
    "\n",
    "    After processing, csv file and item are deleted.\n",
    "\n",
    "    Args:\n",
    "        source_data ([dataframe]): Source data that will be appended to target layer.\n",
    "        target_table ([table]): Target layer that data is appended to\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create a temporary name based on GUID ID\n",
    "        temp_name = uuid.uuid4().hex\n",
    "\n",
    "        # Set path to store files in the same folder as the log file.  \n",
    "        source_path = os.path.dirname(__file__)\n",
    "        source_file_path = os.path.join(source_path, f'{temp_name}.csv')\n",
    "\n",
    "        # convert source data to csv and add to organization\n",
    "        source_data.to_csv(source_file_path)\n",
    "        temp_fc_properties = {\n",
    "                            'title': temp_name,\n",
    "                            'description':'Temporary collection of features.',\n",
    "                            'tags': 'arcgis python api, pandas, featureCollection, Temp, Temporary',\n",
    "                            'type':'CSV'\n",
    "                            }\n",
    "        temp_fc_layer = gis.content.add(item_properties=temp_fc_properties, data=source_file_path)\n",
    "        print(f\"Attempting to append records in {temp_name} on Hosted Feature Layer {target_table.properties.name}\")\n",
    "        source_info = gis.content.analyze(item=temp_fc_layer.id, file_type='csv', location_type='none')\n",
    "    \n",
    "        target_table.append(upload_format='csv',\n",
    "                        item_id=temp_fc_layer.id,\n",
    "                        source_info = source_info['publishParameters'],\n",
    "                        upsert=upsert_flag,\n",
    "                        skip_updates=False,\n",
    "                        skip_inserts=False,\n",
    "                        update_geometry=False,\n",
    "                        use_globalids=False,\n",
    "                        rollback=False,\n",
    "                        upsert_matching_field=matching_field)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to append on Hosted Feature Layer {target_table.properties.name}\")\n",
    "        print(e, exc_info=True)\n",
    "    finally:\n",
    "        # Delete temporary csv and item in the event of an exception\n",
    "        os.remove(source_file_path)\n",
    "        temp_fc_layer.delete()\n",
    "\n",
    "\n",
    "def batch_it(l, n):\n",
    "\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "\n",
    "def connect(org_url: str, login_name: str, user_password: str, profile_name: Optional[str]=None):\n",
    "    \"\"\"Authenticate and connect to an ArcGIS organization. The GIS is used to access, manage\n",
    "    and modify a users content.\n",
    "\n",
    "    Args:\n",
    "        org_url (str): This should be a web address to either an ArcGIS Enterprise portal or to ArcGIS Online in the \n",
    "                       form: <scheme>://<fully_qualified_domain_name>/<web_adaptor> (ArcGIS Enterprise example)\n",
    "        login_name (str): The login user name (case-sensitive).\n",
    "        user_password (str): If a username is provided, a password is expected. This is case-sensitive.\n",
    "        profile_name (str, optional): The name of the profile that the user wishes to use to authenticate, if set, \n",
    "                                      the identified profile will be used to login to the specified GIS. Defaults to None.\n",
    "    \"\"\"\n",
    "    if profile_name:\n",
    "        print(f'Attempting to connect with the credential profile, {profile_name}')\n",
    "        try:\n",
    "            gis = GIS(profile=profile_name)\n",
    "            log_profile_info(gis)\n",
    "            return gis\n",
    "        except Exception as e:\n",
    "            login_failed_message = f\"Unable to connect to {org_url} with the profile '{profile_name}'. Please check your credentials and try again.\"\n",
    "            print(login_failed_message)\n",
    "            return False\n",
    "    else:\n",
    "        print('No profile specified, attempting to connect using username and password')\n",
    "        try:\n",
    "            gis = GIS(url=org_url, username=login_name, password=user_password)\n",
    "            log_profile_info(gis)\n",
    "            return gis\n",
    "        except Exception as e:\n",
    "            login_failed_message = f'Unable to connect to {org_url}. Please check your credentials and try again.'\n",
    "            print(login_failed_message)\n",
    "            return False\n",
    "       \n",
    "        \n",
    "def create_intersect_filter_object(filter_df, batch_count=75) -> List:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        filter_df ([type]): Spatial Dataframe that contains a set of features to be filtered. \n",
    "        batch_count (int, optional): [description]. Defaults to 75.\n",
    "\n",
    "    Returns:\n",
    "        List: A List of :class:`~arcgis.geometry.Geometry` objects\n",
    "    \"\"\"\n",
    "    # List to store intsert filter objects\n",
    "    intersect_filter_objs = list()\n",
    "\n",
    "    # identify layer geometry type\n",
    "    esri_geometry_type = FeatureSet.from_dataframe(filter_df).geometry_type\n",
    "    if esri_geometry_type == 'esriGeometryPoint':\n",
    "        geometry_type = 'points'\n",
    "        update_sets = [filter_df]\n",
    "    elif esri_geometry_type == 'esriGeometryPolygon':\n",
    "        # if geometry is polygon, chunk dataframe into lists based on batch count.\n",
    "        update_sets = list(batch_it(filter_df, batch_count))\n",
    "        geometry_type = 'rings'\n",
    "\n",
    "    for edits in update_sets:\n",
    "        fset = FeatureSet.from_dataframe(edits)\n",
    "        in_sr = fset.features[0].geometry['spatialReference']\n",
    "        combined_geom = list()\n",
    "        combined_geom_dict = dict()\n",
    "        combined_geom_dict['geometry'] = dict()\n",
    "        for feat in fset:\n",
    "            if geometry_type == 'points':\n",
    "                coords = [[feat.geometry['x'], feat.geometry['y']]]\n",
    "                combined_geom.extend(coords)\n",
    "            elif geometry_type == 'rings':\n",
    "                combined_geom.extend(feat.geometry[geometry_type])\n",
    "        combined_geom_dict['geometry'][geometry_type] = combined_geom\n",
    "        combined_geom_dict['geometry']['spatialReference'] = in_sr\n",
    "        filter_obj = intersects((combined_geom_dict['geometry']), sr=None)\n",
    "        intersect_filter_objs.append(filter_obj)\n",
    "\n",
    "    return intersect_filter_objs\n",
    "        \n",
    "               \n",
    "def featureset_to_df(geometry_list, feature_set):\n",
    "    '''\n",
    "    Convert a featureset and a list of updated geometry objects \n",
    "    into a dataframe.\n",
    "    :param geometry_list: List - Required \n",
    "        List of ArcGIS Python API geometry objects. The list\n",
    "        of geometries must match the number of features in\n",
    "        the featureSet. Order is also important whereas the\n",
    "        first geometry list item must pertain to the first \n",
    "        item in the featureSet.\n",
    "    :param feature_set: List - Required\n",
    "        List of ArcGIS Python API FeatureSet objects. The list\n",
    "        of features must match the number of features in\n",
    "        the geometry list. Order is also important whereas the\n",
    "        first feature list item must pertain to the first \n",
    "        item in the geometry list.\n",
    "    :return Spatially enabled Dataframe\n",
    "    '''\n",
    "    # Feature counter\n",
    "    cnt = 0\n",
    "\n",
    "    # Loop through features\n",
    "    feature_list = list()\n",
    "    for geom in geometry_list:\n",
    "        feature_attributes = feature_set.features[cnt].attributes\n",
    "        feat = Feature(geometry=geom, attributes=feature_attributes)\n",
    "        feature_list.append(feat)\n",
    "        cnt += 1\n",
    "    fset = FeatureSet(feature_list)\n",
    "\n",
    "    out_df = fset.sdf\n",
    "\n",
    "    # Ensure datefields are in the correct format\n",
    "    for f in feature_set.fields:\n",
    "        if f['type'] == 'esriFieldTypeDate':\n",
    "            if out_df[f['name']].dtypes != \"datetime64[ns]\":\n",
    "                out_df[f['name']] = pd.to_datetime(out_df[f['name']], unit='ms')\n",
    "\n",
    "    return out_df\n",
    "        \n",
    "        \n",
    "def geometry_based_query(lyr: FeatureLayer, filter_objects: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run a spatially enabled query against a layer based on a list of one or more geometry sets\n",
    "\n",
    "    Args:\n",
    "        lyr (FeatureLayer): Layer to be queried based on the filter object geometry.\n",
    "        filter_objects (List): List of dictionaries that contain a set of geometry objects.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe that contains a set of unique features queried from the lyr.\n",
    "    \"\"\"\n",
    "\n",
    "    total_dfs = list()\n",
    "    for filters in filter_objects:\n",
    "        df = lyr.query(geometry_filter=filters, as_df=True)\n",
    "        total_dfs.append(df)\n",
    "    \n",
    "    # concatenate dataframes together while leaving just unique rows\n",
    "    unique_df = pd.concat(total_dfs).drop_duplicates().reset_index(drop=True)\n",
    "    return unique_df\n",
    "\n",
    "\n",
    "def get_gis_item(item_id: str, gis: GIS) -> Item:\n",
    "    \"\"\" This is a method that retrieves a layer from AGOL or Enterprise by retrieving the layer based\n",
    "        on the item id and the GIS config object\n",
    "\n",
    "    Args:\n",
    "        item_id (str): Item ID of the content that is requested and returned as an item object \n",
    "        gis (arcgis.gis.GIS): GIS authentication object that's passed in to access item.  Note, user must\n",
    "        have access to item in order to fulfill the request.    \n",
    "\n",
    "    Raises:\n",
    "        Exception: Message that is returned in regards to unable to access item.\n",
    "\n",
    "    Returns:\n",
    "        arcgis.gis.Item: Item content object for the requested item id.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to retrieve layer with item id: {item_id}\")\n",
    "    item = gis.content.get(item_id)\n",
    "\n",
    "    if not item:\n",
    "        item_not_found_message = f\"Input Item ID Not Found in GIS: {item_id}\"\n",
    "        print(item_not_found_message)\n",
    "        raise Exception(item_not_found_message)\n",
    "    else:\n",
    "        print(f\"Successfully got GIS Item ID: {item_id}\")\n",
    "        return item\n",
    "\n",
    "\n",
    "def log_profile_info(gis):\n",
    "    '''\n",
    "    Output print statement that displays gis properties\n",
    "    '''\n",
    "    print(\"Successfully logged into '{}' via the user '{}'\".format(\n",
    "        gis.properties.portalHostname,\n",
    "        gis.properties.user.username))\n",
    "\n",
    "\n",
    "def process_edits(feature_layer, data_frame, operation, gis=None, batch_count=20000, matching_field=None, upsert_flag=False):\n",
    "    \"\"\"\n",
    "    Append data to a Push edits from SDF to hosted feature layer.\n",
    "    Args:\n",
    "        feature_layer ([type]): Target layer that data is appended to\n",
    "        data_frame ([type]): Source data that will be appended to target layer.\n",
    "        operation ([type]): [description] TODO\n",
    "        batch_count (int, optional): Maximum Number of records in dataframe that that can be in a\n",
    "                                        set to be appended to target layer. Defaults to 50000.\n",
    "    \"\"\"\n",
    "    print('Processing {} Events.....'.format(len(data_frame)))\n",
    "    print(f\"Running {operation.upper()} on Hosted Feature Layer {feature_layer.properties.name}\")\n",
    "\n",
    "    # Chunk dataframe into lists based on batch count.\n",
    "    update_sets = list(batch_it(data_frame, batch_count))\n",
    "\n",
    "    for edits in update_sets:\n",
    "        try:\n",
    "            if feature_layer.properties.type == 'Table':\n",
    "                append_to_table(edits, feature_layer, gis, matching_field, upsert_flag)\n",
    "            else:\n",
    "                append_to_layer(edits, feature_layer, gis, matching_field, upsert_flag)\n",
    "        except:\n",
    "            print(\"Unable to run %s on Hosted Feature Layer %s\", operation.upper(), feature_layer.properties.name)\n",
    "            print(\"Attempted to run %s on data %s\", operation.upper(), edits.spatial.to_featureset().features)\n",
    "\n",
    "            \n",
    "def query_layer(lyr, fields=None, geometry_flag=True, time_bound=False, geometry_filter_obj=None):\n",
    "    \"\"\"Return dataframe based on a layer query.\"\"\"\n",
    "    # Set time to record time spent running the query method from the python api.\n",
    "    start_time = time.time()\n",
    "\n",
    "    if geometry_filter_obj != None:\n",
    "        print(f\"Running a geometry based query on {lyr.properties.name}\")\n",
    "        df = geometry_based_query(lyr, geometry_filter_obj)\n",
    "    elif time_bound:\n",
    "        print(\"Running time bound query on {}\".format(lyr.properties.name))\n",
    "        clause = time_bound_clause(datetime_field, time_range)\n",
    "        df =  lyr.query(where=clause, return_geometry=geometry_flag, as_df=True)\n",
    "    else:\n",
    "        print(\"Running query on {}\".format(lyr.properties.name))\n",
    "        df =  lyr.query(return_geometry=geometry_flag, as_df=True)\n",
    "\n",
    "    print(f'Completed query of {lyr.properties.name} in {round((time.time() - start_time), 2)} seconds returning {len(df)} features')\n",
    "\n",
    "    # If geometry field is returned + a set of fields, append the geometry field name to the list.\n",
    "    if geometry_flag and fields is not None:\n",
    "        shape_field = df.select_dtypes('geometry').columns[0]\n",
    "        fields.append(shape_field)\n",
    "\n",
    "    # out_fields parameter in the query method does not work if date fields are restricted.\n",
    "    # Must run pandas filter method to restrict fields.\n",
    "    if fields is None:\n",
    "        return df\n",
    "    else:\n",
    "        return df[fields]\n",
    "    \n",
    "def reproject(in_df, out_sr):\n",
    "    \"\"\"\n",
    "    Reproject a dataframe to a new spatial reference.\n",
    "    :param in_df: Spatially enabled Dataframe - Required\n",
    "        Contains a shape field that contains a list of \n",
    "        ArcGIS Python API geometry objects.\n",
    "    :param out_sr: SpatialReference - Required\n",
    "        ArcGIS Python API SpatialReference object specifying the\n",
    "        desired output spatial reference.\n",
    "    :return Dataframe based on the input dataframe but in the new\n",
    "        spatial reference.\n",
    "    \"\"\"\n",
    "    # Ensure \"nan\" Does Not Appear in Aggregate Output Fields\n",
    "    [in_df[col].replace(np.nan, '', regex=True, inplace=True) for col in list(in_df.columns)]\n",
    "\n",
    "    # Convert dataframe into a featureset\n",
    "    feat_set = in_df.spatial.to_featureset()\n",
    "\n",
    "    # Extract the geometry from FeatureSet\n",
    "    in_geom_list = [f.geometry for f in feat_set]\n",
    "\n",
    "    # test to ensure the spatial reference is consistent across all the input geometries\n",
    "    in_wkid_lst = [geom['spatialReference']['wkid'] for geom in in_geom_list]\n",
    "    if len(set(in_wkid_lst)) > 1:\n",
    "        print('All spatial references in the input geometry list must be identical.')\n",
    "        raise Exception(\n",
    "            'All spatial references in the input geometry list must be identical.')\n",
    "\n",
    "    # set the input spatial reference based on the first spatial reference\n",
    "    in_sr = in_geom_list[0]['spatialReference']\n",
    "\n",
    "    # determine if a transformation needs to be applied\n",
    "    transformation_lst = find_transformation(in_sr, out_sr)['transformations']\n",
    "\n",
    "    # use the geometry service to reproject the geometry list using a transformation if needed\n",
    "    if len(transformation_lst):\n",
    "        out_geom_list = project(in_geom_list, in_sr,\n",
    "                                out_sr, transformation_lst[0])\n",
    "    else:\n",
    "        out_geom_list = project(in_geom_list, in_sr, out_sr)\n",
    "\n",
    "    # ensure the output geometries have the spatial reference explicitly defined\n",
    "    for geom in out_geom_list:\n",
    "        geom['spatialReference'] = out_sr\n",
    "\n",
    "    out_df = featureset_to_df(out_geom_list, feat_set)\n",
    "\n",
    "    print(\"Reprojection successful\")\n",
    "    return out_df\n",
    "    \n",
    "    \n",
    "def time_bound_clause(datetime_field: str, time_range: int) -> Text:\n",
    "    \"\"\"Create a where statement to look back at a specified time range in minutes. Time is converted to UTC\n",
    "\n",
    "    Args:\n",
    "        datetime_field (str): Field name from layer that is of the data type datetime.\n",
    "        time_range (int): Value in the unit of minutes.\n",
    "\n",
    "    Returns:\n",
    "        Text: A string formatted as a complete SQL clause. \n",
    "    \"\"\"\n",
    "    look_back_time = (datetime.utcnow() - timedelta(hours=0, minutes=time_range)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    where_clause = f\"{datetime_field} >= timestamp'{look_back_time}'\"\n",
    "\n",
    "    return where_clause"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01054475-9685-43c6-8eb0-8fd7e4e08cdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Grabbing the Layer content from our source and target layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d58aaee0-157a-4439-b7fa-1b60b871eff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to retrieve layer with item id: 59ea577aed334362bf7106c6771c82cf\n",
      "Successfully got GIS Item ID: 59ea577aed334362bf7106c6771c82cf\n",
      "Attempting to retrieve layer with item id: 59ea577aed334362bf7106c6771c82cf\n",
      "Successfully got GIS Item ID: 59ea577aed334362bf7106c6771c82cf\n"
     ]
    }
   ],
   "source": [
    "target_item = get_gis_item(target_item_id, gis)\n",
    "target_lyr = target_item.layers[0]\n",
    "\n",
    "source_item = get_gis_item(source_item_id, gis)\n",
    "source_lyr = source_item.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c342396c-d7e0-4a18-aa15-14e8c57bac2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query on Geoenabled_Chats\n",
      "Completed query of Geoenabled_Chats in 0.54 seconds returning 434 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_id</th>\n",
       "      <th>created</th>\n",
       "      <th>extracted_entity</th>\n",
       "      <th>geocoded_lat</th>\n",
       "      <th>geocoded_long</th>\n",
       "      <th>geocoding_source</th>\n",
       "      <th>message_body</th>\n",
       "      <th>msg_parsed</th>\n",
       "      <th>username</th>\n",
       "      <th>ObjectId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Creator</th>\n",
       "      <th>EditDate</th>\n",
       "      <th>Editor</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63d977160c5d388d24867d7c</td>\n",
       "      <td>2023-01-31 20:16:22.739000082</td>\n",
       "      <td>12SVA8360167751</td>\n",
       "      <td>32.246</td>\n",
       "      <td>-111.174</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>man seen flying near airplane at 12SVA8360167751</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>{\"x\": -12375833.069451395, \"y\": 3795645.443935...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63d9772d0c5d388d24867d7e</td>\n",
       "      <td>2023-01-31 20:16:45.730999947</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>asdfsadfasdfsad</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63d977340c5d388d24867d80</td>\n",
       "      <td>2023-01-31 20:16:52.282999992</td>\n",
       "      <td>10SFJ3955214272</td>\n",
       "      <td>38.966</td>\n",
       "      <td>-121.389</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>16 tanks seen at 10SFJ3955214272</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>{\"x\": -13512961.667904684, \"y\": 4716802.533805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63d9773b0c5d388d24867d82</td>\n",
       "      <td>2023-01-31 20:16:59.154999971</td>\n",
       "      <td>13VFK4119422905</td>\n",
       "      <td>62.411</td>\n",
       "      <td>-102.267</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>Friendly fire, hold your fire 13VFK4119422905</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>{\"x\": -11384310.364955708, \"y\": 8957261.920682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63d977c20c5d388d24867d84</td>\n",
       "      <td>2023-01-31 20:19:14.186000109</td>\n",
       "      <td>09VVD4947855601</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>POI GRID 09VVD4947855601, Killbox 32AY3NE, MAX...</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       F_id                       created extracted_entity  \\\n",
       "0  63d977160c5d388d24867d7c 2023-01-31 20:16:22.739000082  12SVA8360167751   \n",
       "1  63d9772d0c5d388d24867d7e 2023-01-31 20:16:45.730999947             null   \n",
       "2  63d977340c5d388d24867d80 2023-01-31 20:16:52.282999992  10SFJ3955214272   \n",
       "3  63d9773b0c5d388d24867d82 2023-01-31 20:16:59.154999971  13VFK4119422905   \n",
       "4  63d977c20c5d388d24867d84 2023-01-31 20:19:14.186000109  09VVD4947855601   \n",
       "\n",
       "   geocoded_lat  geocoded_long geocoding_source  \\\n",
       "0        32.246       -111.174        GEOPARSER   \n",
       "1          <NA>           <NA>             <NA>   \n",
       "2        38.966       -121.389        GEOPARSER   \n",
       "3        62.411       -102.267        GEOPARSER   \n",
       "4          <NA>           <NA>        GEOPARSER   \n",
       "\n",
       "                                        message_body msg_parsed     username  \\\n",
       "0   man seen flying near airplane at 12SVA8360167751       true  topowright    \n",
       "1                                    asdfsadfasdfsad       true  topowright    \n",
       "2                   16 tanks seen at 10SFJ3955214272       true  topowright    \n",
       "3      Friendly fire, hold your fire 13VFK4119422905       true  topowright    \n",
       "4  POI GRID 09VVD4947855601, Killbox 32AY3NE, MAX...       true  topowright    \n",
       "\n",
       "   ObjectId                  CreationDate           Creator  \\\n",
       "0         1 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "1         2 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "2         3 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "3         4 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "4         5 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "\n",
       "                       EditDate            Editor  \\\n",
       "0 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "1 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "2 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "3 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "4 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "\n",
       "                                               SHAPE  \n",
       "0  {\"x\": -12375833.069451395, \"y\": 3795645.443935...  \n",
       "1                                               None  \n",
       "2  {\"x\": -13512961.667904684, \"y\": 4716802.533805...  \n",
       "3  {\"x\": -11384310.364955708, \"y\": 8957261.920682...  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_df = query_layer(source_lyr)\n",
    "source_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a04ce77-f4a6-4d1e-af87-78579fc2d7b3",
   "metadata": {},
   "source": [
    "### Adding data to a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83876835-52b8-4d8e-a299-1d5898c8cb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_id</th>\n",
       "      <th>created</th>\n",
       "      <th>extracted_entity</th>\n",
       "      <th>geocoded_lat</th>\n",
       "      <th>geocoded_long</th>\n",
       "      <th>geocoding_source</th>\n",
       "      <th>message_body</th>\n",
       "      <th>msg_parsed</th>\n",
       "      <th>username</th>\n",
       "      <th>ObjectId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Creator</th>\n",
       "      <th>EditDate</th>\n",
       "      <th>Editor</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>63d977f30c5d388d24867d88</td>\n",
       "      <td>2023-01-31 20:20:03.417999983</td>\n",
       "      <td>15VUJ5744170724</td>\n",
       "      <td>61.942</td>\n",
       "      <td>-95.717</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>Red Cross emergency assistance needed north of...</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>{\"x\": -10655167.700259766, \"y\": 8845403.111607...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63d97a00062813dbf8d2cf30</td>\n",
       "      <td>2023-01-31 20:28:48.144999981</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>asfsafassa</td>\n",
       "      <td>true</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63d97a03062813dbf8d2cf32</td>\n",
       "      <td>2023-01-31 20:28:51.207999945</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>asdsafdfsad</td>\n",
       "      <td>true</td>\n",
       "      <td>asdfsad</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>63d97a0b062813dbf8d2cf34</td>\n",
       "      <td>2023-01-31 20:28:59.055999994</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>asfsadfsasa</td>\n",
       "      <td>true</td>\n",
       "      <td>asdfsad</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63dae7bb62b2ce310da1c7dc</td>\n",
       "      <td>2023-02-01 22:29:15.355000019</td>\n",
       "      <td>09UVV8718840587</td>\n",
       "      <td>53.614</td>\n",
       "      <td>-129.194</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>16 tanks 09UVV8718840587 seen crossing train t...</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>11</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>{\"x\": -14381810.293546185, \"y\": 7097388.819857...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63dae7c462b2ce310da1c7de</td>\n",
       "      <td>2023-02-01 22:29:24.760999918</td>\n",
       "      <td>12STF8024832026</td>\n",
       "      <td>36.408</td>\n",
       "      <td>-113.451</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>The operation is underway 12STF8024832026</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>12</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>{\"x\": -12629307.54998768, \"y\": 4356907.7485512...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>63dc03ae433eb8d680451795</td>\n",
       "      <td>2023-02-02 18:40:46.553999901</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>asfasdfasdfas</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>13</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>63dd4e4c0206eb01723a48cb</td>\n",
       "      <td>2023-02-03 18:11:24.546000004</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>asdfsadsf</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>14</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>63dde1942d01e82c3cf45179</td>\n",
       "      <td>2023-02-04 04:39:48.914999962</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>being able to send messages locally</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>15</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        F_id                       created extracted_entity  \\\n",
       "6   63d977f30c5d388d24867d88 2023-01-31 20:20:03.417999983  15VUJ5744170724   \n",
       "7   63d97a00062813dbf8d2cf30 2023-01-31 20:28:48.144999981             null   \n",
       "8   63d97a03062813dbf8d2cf32 2023-01-31 20:28:51.207999945             null   \n",
       "9   63d97a0b062813dbf8d2cf34 2023-01-31 20:28:59.055999994             null   \n",
       "10  63dae7bb62b2ce310da1c7dc 2023-02-01 22:29:15.355000019  09UVV8718840587   \n",
       "11  63dae7c462b2ce310da1c7de 2023-02-01 22:29:24.760999918  12STF8024832026   \n",
       "12  63dc03ae433eb8d680451795 2023-02-02 18:40:46.553999901             null   \n",
       "13  63dd4e4c0206eb01723a48cb 2023-02-03 18:11:24.546000004             null   \n",
       "14  63dde1942d01e82c3cf45179 2023-02-04 04:39:48.914999962             null   \n",
       "\n",
       "    geocoded_lat  geocoded_long geocoding_source  \\\n",
       "6         61.942        -95.717        GEOPARSER   \n",
       "7           <NA>           <NA>             <NA>   \n",
       "8           <NA>           <NA>             <NA>   \n",
       "9           <NA>           <NA>             <NA>   \n",
       "10        53.614       -129.194        GEOPARSER   \n",
       "11        36.408       -113.451        GEOPARSER   \n",
       "12          <NA>           <NA>             <NA>   \n",
       "13          <NA>           <NA>             <NA>   \n",
       "14          <NA>           <NA>             <NA>   \n",
       "\n",
       "                                         message_body msg_parsed     username  \\\n",
       "6   Red Cross emergency assistance needed north of...       true  topowright    \n",
       "7                                          asfsafassa       true         <NA>   \n",
       "8                                         asdsafdfsad       true      asdfsad   \n",
       "9                                         asfsadfsasa       true      asdfsad   \n",
       "10  16 tanks 09UVV8718840587 seen crossing train t...       true   topowright   \n",
       "11          The operation is underway 12STF8024832026       true   topowright   \n",
       "12                                      asfasdfasdfas       true   topowright   \n",
       "13                                          asdfsadsf       true   topowright   \n",
       "14               being able to send messages locally        true   topowright   \n",
       "\n",
       "    ObjectId                  CreationDate           Creator  \\\n",
       "6          7 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "7          8 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "8          9 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "9         10 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "10        11 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "11        12 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "12        13 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "13        14 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "14        15 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "\n",
       "                        EditDate            Editor  \\\n",
       "6  2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "7  2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "8  2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "9  2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "10 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "11 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "12 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "13 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "14 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "\n",
       "                                                SHAPE  \n",
       "6   {\"x\": -10655167.700259766, \"y\": 8845403.111607...  \n",
       "7                                                None  \n",
       "8                                                None  \n",
       "9                                                None  \n",
       "10  {\"x\": -14381810.293546185, \"y\": 7097388.819857...  \n",
       "11  {\"x\": -12629307.54998768, \"y\": 4356907.7485512...  \n",
       "12                                               None  \n",
       "13                                               None  \n",
       "14                                               None  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = source_df.iloc[6:15]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d48c3a99-392b-492b-91e1-c54d0387322e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 9 Events.....\n",
      "Running ADD on Hosted Feature Layer Geoenabled_Chats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LyleWright\\Documents\\GitHub\\UsefulPython\\update_feature_service\\.venv\\lib\\site-packages\\arcgis\\features\\geo\\_accessor.py:3450: UserWarning: Discarding nonzero nanoseconds in conversion.\n",
      "  row[f] = int(row[f].to_pydatetime().timestamp() * 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to append records in 731d2406e3c7493b8a04c5db4ff34c43 on Hosted Feature Layer Geoenabled_Chats\n",
      "Unable to append on Hosted Feature Layer Geoenabled_Chats\n",
      "Unable to run %s on Hosted Feature Layer %s ADD Geoenabled_Chats\n",
      "Attempted to run %s on data %s ADD [{\"geometry\": {\"x\": -10655167.700259766, \"y\": 8845403.111607227, \"spatialReference\": {\"wkid\": 102100, \"latestWkid\": 3857}}, \"attributes\": {\"F_id\": \"63d977f30c5d388d24867d88\", \"created\": 1675214403417, \"extracted_entity\": \"15VUJ5744170724\", \"geocoded_lat\": 61.942, \"geocoded_long\": -95.717, \"geocoding_source\": \"GEOPARSER\", \"message_body\": \"Red Cross emergency assistance needed north of palace at 15VUJ5744170724 Mary Kim seen in black car headed north at the following location 10UEE2207680562 in full convoy 10 MAM in odd uniforms seen at 12VXJ7463939627\", \"msg_parsed\": \"true\", \"username\": \"topowright \", \"ObjectId\": 7, \"CreationDate\": 1688157346644, \"Creator\": \"foretify_rbeitel\", \"EditDate\": 1688157346644, \"Editor\": \"foretify_rbeitel\"}}, {\"attributes\": {\"F_id\": \"63d97a00062813dbf8d2cf30\", \"created\": 1675214928144, \"extracted_entity\": \"null\", \"geocoded_lat\": 0.0, \"geocoded_long\": 0.0, \"geocoding_source\": \"\", \"message_body\": \"asfsafassa\", \"msg_parsed\": \"true\", \"username\": \"\", \"ObjectId\": 8, \"CreationDate\": 1688157346644, \"Creator\": \"foretify_rbeitel\", \"EditDate\": 1688157346644, \"Editor\": \"foretify_rbeitel\"}}, {\"attributes\": {\"F_id\": \"63d97a03062813dbf8d2cf32\", \"created\": 1675214931207, \"extracted_entity\": \"null\", \"geocoded_lat\": 0.0, \"geocoded_long\": 0.0, \"geocoding_source\": \"\", \"message_body\": \"asdsafdfsad\", \"msg_parsed\": \"true\", \"username\": \"asdfsad\", \"ObjectId\": 9, \"CreationDate\": 1688157346644, \"Creator\": \"foretify_rbeitel\", \"EditDate\": 1688157346644, \"Editor\": \"foretify_rbeitel\"}}, {\"attributes\": {\"F_id\": \"63d97a0b062813dbf8d2cf34\", \"created\": 1675214939055, \"extracted_entity\": \"null\", \"geocoded_lat\": 0.0, \"geocoded_long\": 0.0, \"geocoding_source\": \"\", \"message_body\": \"asfsadfsasa\", \"msg_parsed\": \"true\", \"username\": \"asdfsad\", \"ObjectId\": 10, \"CreationDate\": 1688157346644, \"Creator\": \"foretify_rbeitel\", \"EditDate\": 1688157346644, \"Editor\": \"foretify_rbeitel\"}}, {\"geometry\": {\"x\": -14381810.293546185, \"y\": 7097388.819857175, \"spatialReference\": {\"wkid\": 102100, \"latestWkid\": 3857}}, \"attributes\": {\"F_id\": \"63dae7bb62b2ce310da1c7dc\", \"created\": 1675308555355, \"extracted_entity\": \"09UVV8718840587\", \"geocoded_lat\": 53.614, \"geocoded_long\": -129.194, \"geocoding_source\": \"GEOPARSER\", \"message_body\": \"16 tanks 09UVV8718840587 seen crossing train tracks\", \"msg_parsed\": \"true\", \"username\": \"topowright\", \"ObjectId\": 11, \"CreationDate\": 1688157346644, \"Creator\": \"foretify_rbeitel\", \"EditDate\": 1688157346644, \"Editor\": \"foretify_rbeitel\"}}, {\"geometry\": {\"x\": -12629307.54998768, \"y\": 4356907.748551277, \"spatialReference\": {\"wkid\": 102100, \"latestWkid\": 3857}}, \"attributes\": {\"F_id\": \"63dae7c462b2ce310da1c7de\", \"created\": 1675308564760, \"extracted_entity\": \"12STF8024832026\", \"geocoded_lat\": 36.408, \"geocoded_long\": -113.451, \"geocoding_source\": \"GEOPARSER\", \"message_body\": \"The operation is underway 12STF8024832026\", \"msg_parsed\": \"true\", \"username\": \"topowright\", \"ObjectId\": 12, \"CreationDate\": 1688157346644, \"Creator\": \"foretify_rbeitel\", \"EditDate\": 1688157346644, \"Editor\": \"foretify_rbeitel\"}}, {\"attributes\": {\"F_id\": \"63dc03ae433eb8d680451795\", \"created\": 1675381246553, \"extracted_entity\": \"null\", \"geocoded_lat\": 0.0, \"geocoded_long\": 0.0, \"geocoding_source\": \"\", \"message_body\": \"asfasdfasdfas\", \"msg_parsed\": \"true\", \"username\": \"topowright\", \"ObjectId\": 13, \"CreationDate\": 1688157346644, \"Creator\": \"foretify_rbeitel\", \"EditDate\": 1688157346644, \"Editor\": \"foretify_rbeitel\"}}, {\"attributes\": {\"F_id\": \"63dd4e4c0206eb01723a48cb\", \"created\": 1675465884546, \"extracted_entity\": \"null\", \"geocoded_lat\": 0.0, \"geocoded_long\": 0.0, \"geocoding_source\": \"\", \"message_body\": \"asdfsadsf\", \"msg_parsed\": \"true\", \"username\": \"topowright\", \"ObjectId\": 14, \"CreationDate\": 1688157346644, \"Creator\": \"foretify_rbeitel\", \"EditDate\": 1688157346644, \"Editor\": \"foretify_rbeitel\"}}, {\"attributes\": {\"F_id\": \"63dde1942d01e82c3cf45179\", \"created\": 1675503588914, \"extracted_entity\": \"null\", \"geocoded_lat\": 0.0, \"geocoded_long\": 0.0, \"geocoding_source\": \"\", \"message_body\": \"being able to send messages locally \", \"msg_parsed\": \"true\", \"username\": \"topowright\", \"ObjectId\": 15, \"CreationDate\": 1688157346644, \"Creator\": \"foretify_rbeitel\", \"EditDate\": 1688157346644, \"Editor\": \"foretify_rbeitel\"}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LyleWright\\Documents\\GitHub\\UsefulPython\\update_feature_service\\.venv\\lib\\site-packages\\arcgis\\features\\geo\\_accessor.py:3450: UserWarning: Discarding nonzero nanoseconds in conversion.\n",
      "  row[f] = int(row[f].to_pydatetime().timestamp() * 1000)\n"
     ]
    }
   ],
   "source": [
    "process_edits(target_lyr, tmp_df, 'add', gis=gis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea3940-4907-4bb7-ae20-7d7d03ff505a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
