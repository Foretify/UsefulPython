{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c0073d-4318-4085-a9ca-a563c82d7a1a",
   "metadata": {},
   "source": [
    "### Enter Item ID Below of Source and Target Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "580e983e-4804-444c-809a-c9caf9923cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Layer details\n",
    "source_item_id = '59ea577aed334362bf7106c6771c82cf'\n",
    "soure_layer_id = 0\n",
    "\n",
    "# Target layer to load data into\n",
    "target_item_id = '59ea577aed334362bf7106c6771c82cf'\n",
    "target_layer_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88582c91-e842-4e49-9d57-31ec39b5beb7",
   "metadata": {},
   "source": [
    "## Logging into your ArcGIS Online Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0240ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c947f42-ac12-403d-8d67-803bf5349df0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `verify_cert` to False is a security risk, use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in as: foretify_proton\n"
     ]
    }
   ],
   "source": [
    "arcgis_org_url=\"https://foretify.maps.arcgis.com/\"\n",
    "username= \"foretify_proton\"\n",
    "#password=getpass.getpass(\"Enter Password: \")\n",
    "password = 'Zion2023!!'\n",
    "gis = GIS(arcgis_org_url, username, password, verify_cert=False)\n",
    "print(\"Successfully logged in as: \" + gis.properties.user.username)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f0d428-582c-45b3-a19e-0bf10375c8f3",
   "metadata": {},
   "source": [
    "## Functions and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95a97d07-8b50-4fe0-ba1c-e832a0e9fdf0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "from configparser import ConfigParser, SafeConfigParser, RawConfigParser\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Dict, Text\n",
    "\n",
    "from arcgis.gis import GIS, Item\n",
    "from arcgis.features import feature, FeatureSet, FeatureCollection, FeatureLayer\n",
    "from arcgis.geometry.filters import intersects\n",
    "from arcgis.geometry import find_transformation, project, SpatialReference\n",
    "\n",
    "\n",
    "def  append_to_layer(source_data, target_layer, gis=None, matching_field=None, upsert_flag=False):\n",
    "    \"\"\"Append a dataframe to a hosted feature layer\n",
    "    \n",
    "    Dataframe is converted to a feature collection and uploaded to users content\n",
    "    in order to be appended to target layer.\n",
    "\n",
    "    After processing, item is deleted.\n",
    "\n",
    "    Args:\n",
    "        source_data ([dataframe]): Source data that will be appended to target layer.\n",
    "        target_layer ([layer]): Target layer that data is appended to\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a temporary name based on GUID ID\n",
    "        temp_name = uuid.uuid4().hex\n",
    "\n",
    "        # convert source data to feature collection and add to organization\n",
    "        fs = FeatureSet.from_dataframe(source_data)\n",
    "        # For cases where just attributes in a target layer are getting updated with no geometry modifications,\n",
    "        # we will need to ensure the geometryType and spatialReference properties match the target layer in order \n",
    "        # to make a feature collection.\n",
    "        if fs.features[0].geometry_type == 'Table':\n",
    "            fs.geometry_type = target_layer.properties.geometryType\n",
    "            fs.spatial_reference = target_layer.properties.extent.spatialReference\n",
    "        feat_collection = FeatureCollection.from_featureset(fs)  \n",
    "        temp_fc_properties = {\n",
    "                            'title': temp_name,\n",
    "                            'description':'Temporary collection of features.',\n",
    "                            'tags': 'arcgis python api, pandas, featureCollection, Temp, Temporary',\n",
    "                            'text': feat_collection._lyr_json,\n",
    "                            'type':'Feature Collection'\n",
    "                            }\n",
    "        temp_fc_layer = gis.content.add(temp_fc_properties)\n",
    "        print(f\"Attempting to append records in {temp_name} on Hosted Feature Layer {target_layer.properties.name}\")\n",
    "\n",
    "        target_layer.append(upload_format='featureCollection',\n",
    "                        item_id=temp_fc_layer.id,\n",
    "                        upsert=upsert_flag,\n",
    "                        skip_updates=False,\n",
    "                        skip_inserts=False,\n",
    "                        update_geometry=False,\n",
    "                        use_globalids=False,\n",
    "                        rollback=False,\n",
    "                        upsert_matching_field=matching_field)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to append on Hosted Feature Layer {target_layer.properties.name}\")\n",
    "        print(e, exc_info=True)\n",
    "    finally:\n",
    "        # Delete temporary item\n",
    "        temp_fc_layer.delete()\n",
    "\n",
    "\n",
    "def append_to_table(source_data, target_table, gis=None, matching_field=None, upsert_flag=False):\n",
    "    \"\"\"Append a dataframe to a hosted table.\n",
    "    \n",
    "    Dataframe is converted to a csv file and saved to the same folder as the log file. File\n",
    "    is then uploaded to users content in order to be appended to target table.\n",
    "\n",
    "    After processing, csv file and item are deleted.\n",
    "\n",
    "    Args:\n",
    "        source_data ([dataframe]): Source data that will be appended to target layer.\n",
    "        target_table ([table]): Target layer that data is appended to\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create a temporary name based on GUID ID\n",
    "        temp_name = uuid.uuid4().hex\n",
    "\n",
    "        # Set path to store files in the same folder as the log file.  \n",
    "        source_path = os.path.dirname(__file__)\n",
    "        source_file_path = os.path.join(source_path, f'{temp_name}.csv')\n",
    "\n",
    "        # convert source data to csv and add to organization\n",
    "        source_data.to_csv(source_file_path)\n",
    "        temp_fc_properties = {\n",
    "                            'title': temp_name,\n",
    "                            'description':'Temporary collection of features.',\n",
    "                            'tags': 'arcgis python api, pandas, featureCollection, Temp, Temporary',\n",
    "                            'type':'CSV'\n",
    "                            }\n",
    "        temp_fc_layer = gis.content.add(item_properties=temp_fc_properties, data=source_file_path)\n",
    "        print(f\"Attempting to append records in {temp_name} on Hosted Feature Layer {target_table.properties.name}\")\n",
    "        source_info = gis.content.analyze(item=temp_fc_layer.id, file_type='csv', location_type='none')\n",
    "    \n",
    "        target_table.append(upload_format='csv',\n",
    "                        item_id=temp_fc_layer.id,\n",
    "                        source_info = source_info['publishParameters'],\n",
    "                        upsert=upsert_flag,\n",
    "                        skip_updates=False,\n",
    "                        skip_inserts=False,\n",
    "                        update_geometry=False,\n",
    "                        use_globalids=False,\n",
    "                        rollback=False,\n",
    "                        upsert_matching_field=matching_field)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to append on Hosted Feature Layer {target_table.properties.name}\")\n",
    "        print(e, exc_info=True)\n",
    "    finally:\n",
    "        # Delete temporary csv and item in the event of an exception\n",
    "        os.remove(source_file_path)\n",
    "        temp_fc_layer.delete()\n",
    "\n",
    "\n",
    "def batch_it(l, n):\n",
    "\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "\n",
    "def connect(org_url: str, login_name: str, user_password: str, profile_name: Optional[str]=None):\n",
    "    \"\"\"Authenticate and connect to an ArcGIS organization. The GIS is used to access, manage\n",
    "    and modify a users content.\n",
    "\n",
    "    Args:\n",
    "        org_url (str): This should be a web address to either an ArcGIS Enterprise portal or to ArcGIS Online in the \n",
    "                       form: <scheme>://<fully_qualified_domain_name>/<web_adaptor> (ArcGIS Enterprise example)\n",
    "        login_name (str): The login user name (case-sensitive).\n",
    "        user_password (str): If a username is provided, a password is expected. This is case-sensitive.\n",
    "        profile_name (str, optional): The name of the profile that the user wishes to use to authenticate, if set, \n",
    "                                      the identified profile will be used to login to the specified GIS. Defaults to None.\n",
    "    \"\"\"\n",
    "    if profile_name:\n",
    "        print(f'Attempting to connect with the credential profile, {profile_name}')\n",
    "        try:\n",
    "            gis = GIS(profile=profile_name)\n",
    "            log_profile_info(gis)\n",
    "            return gis\n",
    "        except Exception as e:\n",
    "            login_failed_message = f\"Unable to connect to {org_url} with the profile '{profile_name}'. Please check your credentials and try again.\"\n",
    "            print(login_failed_message)\n",
    "            return False\n",
    "    else:\n",
    "        print('No profile specified, attempting to connect using username and password')\n",
    "        try:\n",
    "            gis = GIS(url=org_url, username=login_name, password=user_password)\n",
    "            log_profile_info(gis)\n",
    "            return gis\n",
    "        except Exception as e:\n",
    "            login_failed_message = f'Unable to connect to {org_url}. Please check your credentials and try again.'\n",
    "            print(login_failed_message)\n",
    "            return False\n",
    "       \n",
    "        \n",
    "def create_intersect_filter_object(filter_df, batch_count=75) -> List:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        filter_df ([type]): Spatial Dataframe that contains a set of features to be filtered. \n",
    "        batch_count (int, optional): [description]. Defaults to 75.\n",
    "\n",
    "    Returns:\n",
    "        List: A List of :class:`~arcgis.geometry.Geometry` objects\n",
    "    \"\"\"\n",
    "    # List to store intsert filter objects\n",
    "    intersect_filter_objs = list()\n",
    "\n",
    "    # identify layer geometry type\n",
    "    esri_geometry_type = FeatureSet.from_dataframe(filter_df).geometry_type\n",
    "    if esri_geometry_type == 'esriGeometryPoint':\n",
    "        geometry_type = 'points'\n",
    "        update_sets = [filter_df]\n",
    "    elif esri_geometry_type == 'esriGeometryPolygon':\n",
    "        # if geometry is polygon, chunk dataframe into lists based on batch count.\n",
    "        update_sets = list(batch_it(filter_df, batch_count))\n",
    "        geometry_type = 'rings'\n",
    "\n",
    "    for edits in update_sets:\n",
    "        fset = FeatureSet.from_dataframe(edits)\n",
    "        in_sr = fset.features[0].geometry['spatialReference']\n",
    "        combined_geom = list()\n",
    "        combined_geom_dict = dict()\n",
    "        combined_geom_dict['geometry'] = dict()\n",
    "        for feat in fset:\n",
    "            if geometry_type == 'points':\n",
    "                coords = [[feat.geometry['x'], feat.geometry['y']]]\n",
    "                combined_geom.extend(coords)\n",
    "            elif geometry_type == 'rings':\n",
    "                combined_geom.extend(feat.geometry[geometry_type])\n",
    "        combined_geom_dict['geometry'][geometry_type] = combined_geom\n",
    "        combined_geom_dict['geometry']['spatialReference'] = in_sr\n",
    "        filter_obj = intersects((combined_geom_dict['geometry']), sr=None)\n",
    "        intersect_filter_objs.append(filter_obj)\n",
    "\n",
    "    return intersect_filter_objs\n",
    "        \n",
    "               \n",
    "def featureset_to_df(geometry_list, feature_set):\n",
    "    '''\n",
    "    Convert a featureset and a list of updated geometry objects \n",
    "    into a dataframe.\n",
    "    :param geometry_list: List - Required \n",
    "        List of ArcGIS Python API geometry objects. The list\n",
    "        of geometries must match the number of features in\n",
    "        the featureSet. Order is also important whereas the\n",
    "        first geometry list item must pertain to the first \n",
    "        item in the featureSet.\n",
    "    :param feature_set: List - Required\n",
    "        List of ArcGIS Python API FeatureSet objects. The list\n",
    "        of features must match the number of features in\n",
    "        the geometry list. Order is also important whereas the\n",
    "        first feature list item must pertain to the first \n",
    "        item in the geometry list.\n",
    "    :return Spatially enabled Dataframe\n",
    "    '''\n",
    "    # Feature counter\n",
    "    cnt = 0\n",
    "\n",
    "    # Loop through features\n",
    "    feature_list = list()\n",
    "    for geom in geometry_list:\n",
    "        feature_attributes = feature_set.features[cnt].attributes\n",
    "        feat = Feature(geometry=geom, attributes=feature_attributes)\n",
    "        feature_list.append(feat)\n",
    "        cnt += 1\n",
    "    fset = FeatureSet(feature_list)\n",
    "\n",
    "    out_df = fset.sdf\n",
    "\n",
    "    # Ensure datefields are in the correct format\n",
    "    for f in feature_set.fields:\n",
    "        if f['type'] == 'esriFieldTypeDate':\n",
    "            if out_df[f['name']].dtypes != \"datetime64[ns]\":\n",
    "                out_df[f['name']] = pd.to_datetime(out_df[f['name']], unit='ms')\n",
    "\n",
    "    return out_df\n",
    "        \n",
    "        \n",
    "def geometry_based_query(lyr: FeatureLayer, filter_objects: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run a spatially enabled query against a layer based on a list of one or more geometry sets\n",
    "\n",
    "    Args:\n",
    "        lyr (FeatureLayer): Layer to be queried based on the filter object geometry.\n",
    "        filter_objects (List): List of dictionaries that contain a set of geometry objects.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe that contains a set of unique features queried from the lyr.\n",
    "    \"\"\"\n",
    "\n",
    "    total_dfs = list()\n",
    "    for filters in filter_objects:\n",
    "        df = lyr.query(geometry_filter=filters, as_df=True)\n",
    "        total_dfs.append(df)\n",
    "    \n",
    "    # concatenate dataframes together while leaving just unique rows\n",
    "    unique_df = pd.concat(total_dfs).drop_duplicates().reset_index(drop=True)\n",
    "    return unique_df\n",
    "\n",
    "\n",
    "def get_gis_item(item_id: str, gis: GIS) -> Item:\n",
    "    \"\"\" This is a method that retrieves a layer from AGOL or Enterprise by retrieving the layer based\n",
    "        on the item id and the GIS config object\n",
    "\n",
    "    Args:\n",
    "        item_id (str): Item ID of the content that is requested and returned as an item object \n",
    "        gis (arcgis.gis.GIS): GIS authentication object that's passed in to access item.  Note, user must\n",
    "        have access to item in order to fulfill the request.    \n",
    "\n",
    "    Raises:\n",
    "        Exception: Message that is returned in regards to unable to access item.\n",
    "\n",
    "    Returns:\n",
    "        arcgis.gis.Item: Item content object for the requested item id.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to retrieve layer with item id: {item_id}\")\n",
    "    item = gis.content.get(item_id)\n",
    "\n",
    "    if not item:\n",
    "        item_not_found_message = f\"Input Item ID Not Found in GIS: {item_id}\"\n",
    "        print(item_not_found_message)\n",
    "        raise Exception(item_not_found_message)\n",
    "    else:\n",
    "        print(f\"Successfully got GIS Item ID: {item_id}\")\n",
    "        return item\n",
    "\n",
    "\n",
    "def log_profile_info(gis):\n",
    "    '''\n",
    "    Output print statement that displays gis properties\n",
    "    '''\n",
    "    print(\"Successfully logged into '{}' via the user '{}'\".format(\n",
    "        gis.properties.portalHostname,\n",
    "        gis.properties.user.username))\n",
    "\n",
    "\n",
    "def process_edits(feature_layer, data_frame, operation, gis=None, batch_count=20000, matching_field=None, upsert_flag=False):\n",
    "    \"\"\"\n",
    "    Append data to a Push edits from SDF to hosted feature layer.\n",
    "    Args:\n",
    "        feature_layer ([type]): Target layer that data is appended to\n",
    "        data_frame ([type]): Source data that will be appended to target layer.\n",
    "        operation ([type]): [description] TODO\n",
    "        batch_count (int, optional): Maximum Number of records in dataframe that that can be in a\n",
    "                                        set to be appended to target layer. Defaults to 50000.\n",
    "    \"\"\"\n",
    "    print('Processing {} Events.....'.format(len(data_frame)))\n",
    "    print(f\"Running {operation.upper()} on Hosted Feature Layer {feature_layer.properties.name}\")\n",
    "\n",
    "    # Chunk dataframe into lists based on batch count.\n",
    "    update_sets = list(batch_it(data_frame, batch_count))\n",
    "\n",
    "    for edits in update_sets:\n",
    "        try:\n",
    "            if feature_layer.properties.type == 'Table':\n",
    "                append_to_table(edits, feature_layer, gis, matching_field, upsert_flag)\n",
    "            else:\n",
    "                append_to_layer(edits, feature_layer, gis, matching_field, upsert_flag)\n",
    "        except:\n",
    "            print(\"Unable to run %s on Hosted Feature Layer %s\", operation.upper(), feature_layer.properties.name)\n",
    "            print(\"Attempted to run %s on data %s\", operation.upper(), edits.spatial.to_featureset().features)\n",
    "\n",
    "            \n",
    "def query_layer(lyr, fields=None, geometry_flag=True, time_bound=False, geometry_filter_obj=None):\n",
    "    \"\"\"Return dataframe based on a layer query.\"\"\"\n",
    "    # Set time to record time spent running the query method from the python api.\n",
    "    start_time = time.time()\n",
    "\n",
    "    if geometry_filter_obj != None:\n",
    "        print(f\"Running a geometry based query on {lyr.properties.name}\")\n",
    "        df = geometry_based_query(lyr, geometry_filter_obj)\n",
    "    elif time_bound:\n",
    "        print(\"Running time bound query on {}\".format(lyr.properties.name))\n",
    "        clause = time_bound_clause(datetime_field, time_range)\n",
    "        df =  lyr.query(where=clause, return_geometry=geometry_flag, as_df=True)\n",
    "    else:\n",
    "        print(\"Running query on {}\".format(lyr.properties.name))\n",
    "        df =  lyr.query(return_geometry=geometry_flag, as_df=True)\n",
    "\n",
    "    print(f'Completed query of {lyr.properties.name} in {round((time.time() - start_time), 2)} seconds returning {len(df)} features')\n",
    "\n",
    "    # If geometry field is returned + a set of fields, append the geometry field name to the list.\n",
    "    if geometry_flag and fields is not None:\n",
    "        shape_field = df.select_dtypes('geometry').columns[0]\n",
    "        fields.append(shape_field)\n",
    "\n",
    "    # out_fields parameter in the query method does not work if date fields are restricted.\n",
    "    # Must run pandas filter method to restrict fields.\n",
    "    if fields is None:\n",
    "        return df\n",
    "    else:\n",
    "        return df[fields]\n",
    "    \n",
    "def reproject(in_df, out_sr):\n",
    "    \"\"\"\n",
    "    Reproject a dataframe to a new spatial reference.\n",
    "    :param in_df: Spatially enabled Dataframe - Required\n",
    "        Contains a shape field that contains a list of \n",
    "        ArcGIS Python API geometry objects.\n",
    "    :param out_sr: SpatialReference - Required\n",
    "        ArcGIS Python API SpatialReference object specifying the\n",
    "        desired output spatial reference.\n",
    "    :return Dataframe based on the input dataframe but in the new\n",
    "        spatial reference.\n",
    "    \"\"\"\n",
    "    # Ensure \"nan\" Does Not Appear in Aggregate Output Fields\n",
    "    [in_df[col].replace(np.nan, '', regex=True, inplace=True) for col in list(in_df.columns)]\n",
    "\n",
    "    # Convert dataframe into a featureset\n",
    "    feat_set = in_df.spatial.to_featureset()\n",
    "\n",
    "    # Extract the geometry from FeatureSet\n",
    "    in_geom_list = [f.geometry for f in feat_set]\n",
    "\n",
    "    # test to ensure the spatial reference is consistent across all the input geometries\n",
    "    in_wkid_lst = [geom['spatialReference']['wkid'] for geom in in_geom_list]\n",
    "    if len(set(in_wkid_lst)) > 1:\n",
    "        print('All spatial references in the input geometry list must be identical.')\n",
    "        raise Exception(\n",
    "            'All spatial references in the input geometry list must be identical.')\n",
    "\n",
    "    # set the input spatial reference based on the first spatial reference\n",
    "    in_sr = in_geom_list[0]['spatialReference']\n",
    "\n",
    "    # determine if a transformation needs to be applied\n",
    "    transformation_lst = find_transformation(in_sr, out_sr)['transformations']\n",
    "\n",
    "    # use the geometry service to reproject the geometry list using a transformation if needed\n",
    "    if len(transformation_lst):\n",
    "        out_geom_list = project(in_geom_list, in_sr,\n",
    "                                out_sr, transformation_lst[0])\n",
    "    else:\n",
    "        out_geom_list = project(in_geom_list, in_sr, out_sr)\n",
    "\n",
    "    # ensure the output geometries have the spatial reference explicitly defined\n",
    "    for geom in out_geom_list:\n",
    "        geom['spatialReference'] = out_sr\n",
    "\n",
    "    out_df = featureset_to_df(out_geom_list, feat_set)\n",
    "\n",
    "    print(\"Reprojection successful\")\n",
    "    return out_df\n",
    "    \n",
    "    \n",
    "def time_bound_clause(datetime_field: str, time_range: int) -> Text:\n",
    "    \"\"\"Create a where statement to look back at a specified time range in minutes. Time is converted to UTC\n",
    "\n",
    "    Args:\n",
    "        datetime_field (str): Field name from layer that is of the data type datetime.\n",
    "        time_range (int): Value in the unit of minutes.\n",
    "\n",
    "    Returns:\n",
    "        Text: A string formatted as a complete SQL clause. \n",
    "    \"\"\"\n",
    "    look_back_time = (datetime.utcnow() - timedelta(hours=0, minutes=time_range)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    where_clause = f\"{datetime_field} >= timestamp'{look_back_time}'\"\n",
    "\n",
    "    return where_clause"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01054475-9685-43c6-8eb0-8fd7e4e08cdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Grabbing the Layer content from our source and target layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58aaee0-157a-4439-b7fa-1b60b871eff0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to retrieve layer with item id: 59ea577aed334362bf7106c6771c82cf\n",
      "Successfully got GIS Item ID: 59ea577aed334362bf7106c6771c82cf\n",
      "Attempting to retrieve layer with item id: 59ea577aed334362bf7106c6771c82cf\n",
      "Successfully got GIS Item ID: 59ea577aed334362bf7106c6771c82cf\n"
     ]
    }
   ],
   "source": [
    "target_item = get_gis_item(target_item_id, gis)\n",
    "target_lyr = target_item.layers[0]\n",
    "\n",
    "source_item = get_gis_item(source_item_id, gis)\n",
    "source_lyr = source_item.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c342396c-d7e0-4a18-aa15-14e8c57bac2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query on Geoenabled_Chats\n",
      "Completed query of Geoenabled_Chats in 0.39 seconds returning 1 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_id</th>\n",
       "      <th>created</th>\n",
       "      <th>extracted_entity</th>\n",
       "      <th>geocoded_lat</th>\n",
       "      <th>geocoded_long</th>\n",
       "      <th>geocoding_source</th>\n",
       "      <th>message_body</th>\n",
       "      <th>msg_parsed</th>\n",
       "      <th>username</th>\n",
       "      <th>ObjectId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Creator</th>\n",
       "      <th>EditDate</th>\n",
       "      <th>Editor</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232</td>\n",
       "      <td>2023-12-13 12:15:00</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>asdf</td>\n",
       "      <td>asdfasdf</td>\n",
       "      <td>asdfasd</td>\n",
       "      <td>topowright</td>\n",
       "      <td>459</td>\n",
       "      <td>2023-12-11 21:01:53.236000061</td>\n",
       "      <td>foretify_proton</td>\n",
       "      <td>2023-12-11 21:02:20.821000099</td>\n",
       "      <td>foretify_proton</td>\n",
       "      <td>{\"x\": -13549512.913515791, \"y\": 4744556.551021...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  F_id             created extracted_entity  geocoded_lat  geocoded_long  \\\n",
       "0  232 2023-12-13 12:15:00             <NA>          35.0           35.0   \n",
       "\n",
       "  geocoding_source message_body msg_parsed    username  ObjectId  \\\n",
       "0             asdf     asdfasdf    asdfasd  topowright       459   \n",
       "\n",
       "                   CreationDate          Creator  \\\n",
       "0 2023-12-11 21:01:53.236000061  foretify_proton   \n",
       "\n",
       "                       EditDate           Editor  \\\n",
       "0 2023-12-11 21:02:20.821000099  foretify_proton   \n",
       "\n",
       "                                               SHAPE  \n",
       "0  {\"x\": -13549512.913515791, \"y\": 4744556.551021...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_df = query_layer(source_lyr)\n",
    "source_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a04ce77-f4a6-4d1e-af87-78579fc2d7b3",
   "metadata": {},
   "source": [
    "### Adding data to a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83876835-52b8-4d8e-a299-1d5898c8cb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_id</th>\n",
       "      <th>created</th>\n",
       "      <th>extracted_entity</th>\n",
       "      <th>geocoded_lat</th>\n",
       "      <th>geocoded_long</th>\n",
       "      <th>geocoding_source</th>\n",
       "      <th>message_body</th>\n",
       "      <th>msg_parsed</th>\n",
       "      <th>username</th>\n",
       "      <th>ObjectId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Creator</th>\n",
       "      <th>EditDate</th>\n",
       "      <th>Editor</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [F_id, created, extracted_entity, geocoded_lat, geocoded_long, geocoding_source, message_body, msg_parsed, username, ObjectId, CreationDate, Creator, EditDate, Editor, SHAPE]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = source_df.iloc[6:15]\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d48c3a99-392b-492b-91e1-c54d0387322e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 Events.....\n",
      "Running ADD on Hosted Feature Layer Geoenabled_Chats\n"
     ]
    }
   ],
   "source": [
    "process_edits(target_lyr, tmp_df, 'add', gis=gis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea3940-4907-4bb7-ae20-7d7d03ff505a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249fc08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
