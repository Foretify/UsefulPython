{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c04467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcgis\n",
    "from arcgis.gis import GIS\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835b5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(arcgis.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1055e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcgis_org_url=\"https://foretify.maps.arcgis.com/\"\n",
    "username= \"foretify_proton\"\n",
    "password='Zion2023!!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ac8559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `verify_cert` to False is a security risk, use at your own risk.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully logged in as: foretify_proton\n"
     ]
    }
   ],
   "source": [
    "gis = GIS(arcgis_org_url, username, password, verify_cert=False)\n",
    "print(\"Successfully logged in as: \" + gis.properties.user.username)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8453b",
   "metadata": {},
   "source": [
    "### Functions and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1abcf30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "from configparser import ConfigParser, SafeConfigParser, RawConfigParser\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Dict, Text\n",
    "\n",
    "from arcgis.gis import GIS, Item\n",
    "from arcgis.features import feature, FeatureSet, FeatureCollection, FeatureLayer\n",
    "from arcgis.geometry.filters import intersects\n",
    "from arcgis.geometry import find_transformation, project, SpatialReference\n",
    "\n",
    "\n",
    "def  append_to_layer(source_data, target_layer, gis=None, matching_field=None, upsert_flag=False):\n",
    "    \"\"\"Append a dataframe to a hosted feature layer\n",
    "    \n",
    "    Dataframe is converted to a feature collection and uploaded to users content\n",
    "    in order to be appended to target layer.\n",
    "\n",
    "    After processing, item is deleted.\n",
    "\n",
    "    Args:\n",
    "        source_data ([dataframe]): Source data that will be appended to target layer.\n",
    "        target_layer ([layer]): Target layer that data is appended to\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a temporary name based on GUID ID\n",
    "        temp_name = uuid.uuid4().hex\n",
    "\n",
    "        # convert source data to feature collection and add to organization\n",
    "        fs = FeatureSet.from_dataframe(source_data)\n",
    "        # For cases where just attributes in a target layer are getting updated with no geometry modifications,\n",
    "        # we will need to ensure the geometryType and spatialReference properties match the target layer in order \n",
    "        # to make a feature collection.\n",
    "        if fs.features[0].geometry_type == 'Table':\n",
    "            fs.geometry_type = target_layer.properties.geometryType\n",
    "            fs.spatial_reference = target_layer.properties.extent.spatialReference\n",
    "        feat_collection = FeatureCollection.from_featureset(fs)  \n",
    "        temp_fc_properties = {\n",
    "                            'title': temp_name,\n",
    "                            'description':'Temporary collection of features.',\n",
    "                            'tags': 'arcgis python api, pandas, featureCollection, Temp, Temporary',\n",
    "                            'text': feat_collection._lyr_json,\n",
    "                            'type':'Feature Collection'\n",
    "                            }\n",
    "        temp_fc_layer = gis.content.add(temp_fc_properties)\n",
    "        print(f\"Attempting to append records in {temp_name} on Hosted Feature Layer {target_layer.properties.name}\")\n",
    "\n",
    "        target_layer.append(upload_format='featureCollection',\n",
    "                        item_id=temp_fc_layer.id,\n",
    "                        upsert=upsert_flag,\n",
    "                        skip_updates=False,\n",
    "                        skip_inserts=False,\n",
    "                        update_geometry=False,\n",
    "                        use_globalids=False,\n",
    "                        rollback=False,\n",
    "                        upsert_matching_field=matching_field)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to append on Hosted Feature Layer {target_layer.properties.name}\")\n",
    "        print(e, exc_info=True)\n",
    "    finally:\n",
    "        # Delete temporary item\n",
    "        temp_fc_layer.delete()\n",
    "\n",
    "\n",
    "def append_to_table(source_data, target_table, gis=None, matching_field=None, upsert_flag=False):\n",
    "    \"\"\"Append a dataframe to a hosted table.\n",
    "    \n",
    "    Dataframe is converted to a csv file and saved to the same folder as the log file. File\n",
    "    is then uploaded to users content in order to be appended to target table.\n",
    "\n",
    "    After processing, csv file and item are deleted.\n",
    "\n",
    "    Args:\n",
    "        source_data ([dataframe]): Source data that will be appended to target layer.\n",
    "        target_table ([table]): Target layer that data is appended to\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Create a temporary name based on GUID ID\n",
    "        temp_name = uuid.uuid4().hex\n",
    "\n",
    "        # Set path to store files in the same folder as the log file.  \n",
    "        source_path = os.path.dirname(__file__)\n",
    "        source_file_path = os.path.join(source_path, f'{temp_name}.csv')\n",
    "\n",
    "        # convert source data to csv and add to organization\n",
    "        source_data.to_csv(source_file_path)\n",
    "        temp_fc_properties = {\n",
    "                            'title': temp_name,\n",
    "                            'description':'Temporary collection of features.',\n",
    "                            'tags': 'arcgis python api, pandas, featureCollection, Temp, Temporary',\n",
    "                            'type':'CSV'\n",
    "                            }\n",
    "        temp_fc_layer = gis.content.add(item_properties=temp_fc_properties, data=source_file_path)\n",
    "        print(f\"Attempting to append records in {temp_name} on Hosted Feature Layer {target_table.properties.name}\")\n",
    "        source_info = gis.content.analyze(item=temp_fc_layer.id, file_type='csv', location_type='none')\n",
    "    \n",
    "        target_table.append(upload_format='csv',\n",
    "                        item_id=temp_fc_layer.id,\n",
    "                        source_info = source_info['publishParameters'],\n",
    "                        upsert=upsert_flag,\n",
    "                        skip_updates=False,\n",
    "                        skip_inserts=False,\n",
    "                        update_geometry=False,\n",
    "                        use_globalids=False,\n",
    "                        rollback=False,\n",
    "                        upsert_matching_field=matching_field)\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to append on Hosted Feature Layer {target_table.properties.name}\")\n",
    "        print(e, exc_info=True)\n",
    "    finally:\n",
    "        # Delete temporary csv and item in the event of an exception\n",
    "        os.remove(source_file_path)\n",
    "        temp_fc_layer.delete()\n",
    "\n",
    "\n",
    "def batch_it(l, n):\n",
    "\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "\n",
    "def connect(org_url: str, login_name: str, user_password: str, profile_name: Optional[str]=None):\n",
    "    \"\"\"Authenticate and connect to an ArcGIS organization. The GIS is used to access, manage\n",
    "    and modify a users content.\n",
    "\n",
    "    Args:\n",
    "        org_url (str): This should be a web address to either an ArcGIS Enterprise portal or to ArcGIS Online in the \n",
    "                       form: <scheme>://<fully_qualified_domain_name>/<web_adaptor> (ArcGIS Enterprise example)\n",
    "        login_name (str): The login user name (case-sensitive).\n",
    "        user_password (str): If a username is provided, a password is expected. This is case-sensitive.\n",
    "        profile_name (str, optional): The name of the profile that the user wishes to use to authenticate, if set, \n",
    "                                      the identified profile will be used to login to the specified GIS. Defaults to None.\n",
    "    \"\"\"\n",
    "    if profile_name:\n",
    "        print(f'Attempting to connect with the credential profile, {profile_name}')\n",
    "        try:\n",
    "            gis = GIS(profile=profile_name)\n",
    "            log_profile_info(gis)\n",
    "            return gis\n",
    "        except Exception as e:\n",
    "            login_failed_message = f\"Unable to connect to {org_url} with the profile '{profile_name}'. Please check your credentials and try again.\"\n",
    "            print(login_failed_message)\n",
    "            return False\n",
    "    else:\n",
    "        print('No profile specified, attempting to connect using username and password')\n",
    "        try:\n",
    "            gis = GIS(url=org_url, username=login_name, password=user_password)\n",
    "            log_profile_info(gis)\n",
    "            return gis\n",
    "        except Exception as e:\n",
    "            login_failed_message = f'Unable to connect to {org_url}. Please check your credentials and try again.'\n",
    "            print(login_failed_message)\n",
    "            return False\n",
    "       \n",
    "        \n",
    "def create_intersect_filter_object(filter_df, batch_count=75) -> List:\n",
    "    \"\"\"[summary]\n",
    "\n",
    "    Args:\n",
    "        filter_df ([type]): Spatial Dataframe that contains a set of features to be filtered. \n",
    "        batch_count (int, optional): [description]. Defaults to 75.\n",
    "\n",
    "    Returns:\n",
    "        List: A List of :class:`~arcgis.geometry.Geometry` objects\n",
    "    \"\"\"\n",
    "    # List to store intsert filter objects\n",
    "    intersect_filter_objs = list()\n",
    "\n",
    "    # identify layer geometry type\n",
    "    esri_geometry_type = FeatureSet.from_dataframe(filter_df).geometry_type\n",
    "    if esri_geometry_type == 'esriGeometryPoint':\n",
    "        geometry_type = 'points'\n",
    "        update_sets = [filter_df]\n",
    "    elif esri_geometry_type == 'esriGeometryPolygon':\n",
    "        # if geometry is polygon, chunk dataframe into lists based on batch count.\n",
    "        update_sets = list(batch_it(filter_df, batch_count))\n",
    "        geometry_type = 'rings'\n",
    "\n",
    "    for edits in update_sets:\n",
    "        fset = FeatureSet.from_dataframe(edits)\n",
    "        in_sr = fset.features[0].geometry['spatialReference']\n",
    "        combined_geom = list()\n",
    "        combined_geom_dict = dict()\n",
    "        combined_geom_dict['geometry'] = dict()\n",
    "        for feat in fset:\n",
    "            if geometry_type == 'points':\n",
    "                coords = [[feat.geometry['x'], feat.geometry['y']]]\n",
    "                combined_geom.extend(coords)\n",
    "            elif geometry_type == 'rings':\n",
    "                combined_geom.extend(feat.geometry[geometry_type])\n",
    "        combined_geom_dict['geometry'][geometry_type] = combined_geom\n",
    "        combined_geom_dict['geometry']['spatialReference'] = in_sr\n",
    "        filter_obj = intersects((combined_geom_dict['geometry']), sr=None)\n",
    "        intersect_filter_objs.append(filter_obj)\n",
    "\n",
    "    return intersect_filter_objs\n",
    "        \n",
    "               \n",
    "def featureset_to_df(geometry_list, feature_set):\n",
    "    '''\n",
    "    Convert a featureset and a list of updated geometry objects \n",
    "    into a dataframe.\n",
    "    :param geometry_list: List - Required \n",
    "        List of ArcGIS Python API geometry objects. The list\n",
    "        of geometries must match the number of features in\n",
    "        the featureSet. Order is also important whereas the\n",
    "        first geometry list item must pertain to the first \n",
    "        item in the featureSet.\n",
    "    :param feature_set: List - Required\n",
    "        List of ArcGIS Python API FeatureSet objects. The list\n",
    "        of features must match the number of features in\n",
    "        the geometry list. Order is also important whereas the\n",
    "        first feature list item must pertain to the first \n",
    "        item in the geometry list.\n",
    "    :return Spatially enabled Dataframe\n",
    "    '''\n",
    "    # Feature counter\n",
    "    cnt = 0\n",
    "\n",
    "    # Loop through features\n",
    "    feature_list = list()\n",
    "    for geom in geometry_list:\n",
    "        feature_attributes = feature_set.features[cnt].attributes\n",
    "        feat = Feature(geometry=geom, attributes=feature_attributes)\n",
    "        feature_list.append(feat)\n",
    "        cnt += 1\n",
    "    fset = FeatureSet(feature_list)\n",
    "\n",
    "    out_df = fset.sdf\n",
    "\n",
    "    # Ensure datefields are in the correct format\n",
    "    for f in feature_set.fields:\n",
    "        if f['type'] == 'esriFieldTypeDate':\n",
    "            if out_df[f['name']].dtypes != \"datetime64[ns]\":\n",
    "                out_df[f['name']] = pd.to_datetime(out_df[f['name']], unit='ms')\n",
    "\n",
    "    return out_df\n",
    "        \n",
    "        \n",
    "def geometry_based_query(lyr: FeatureLayer, filter_objects: List[Dict]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run a spatially enabled query against a layer based on a list of one or more geometry sets\n",
    "\n",
    "    Args:\n",
    "        lyr (FeatureLayer): Layer to be queried based on the filter object geometry.\n",
    "        filter_objects (List): List of dictionaries that contain a set of geometry objects.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe that contains a set of unique features queried from the lyr.\n",
    "    \"\"\"\n",
    "\n",
    "    total_dfs = list()\n",
    "    for filters in filter_objects:\n",
    "        df = lyr.query(geometry_filter=filters, as_df=True)\n",
    "        total_dfs.append(df)\n",
    "    \n",
    "    # concatenate dataframes together while leaving just unique rows\n",
    "    unique_df = pd.concat(total_dfs).drop_duplicates().reset_index(drop=True)\n",
    "    return unique_df\n",
    "\n",
    "\n",
    "def get_gis_item(item_id: str, gis: GIS) -> Item:\n",
    "    \"\"\" This is a method that retrieves a layer from AGOL or Enterprise by retrieving the layer based\n",
    "        on the item id and the GIS config object\n",
    "\n",
    "    Args:\n",
    "        item_id (str): Item ID of the content that is requested and returned as an item object \n",
    "        gis (arcgis.gis.GIS): GIS authentication object that's passed in to access item.  Note, user must\n",
    "        have access to item in order to fulfill the request.    \n",
    "\n",
    "    Raises:\n",
    "        Exception: Message that is returned in regards to unable to access item.\n",
    "\n",
    "    Returns:\n",
    "        arcgis.gis.Item: Item content object for the requested item id.\n",
    "    \"\"\"\n",
    "    print(f\"Attempting to retrieve layer with item id: {item_id}\")\n",
    "    item = gis.content.get(item_id)\n",
    "\n",
    "    if not item:\n",
    "        item_not_found_message = f\"Input Item ID Not Found in GIS: {item_id}\"\n",
    "        print(item_not_found_message)\n",
    "        raise Exception(item_not_found_message)\n",
    "    else:\n",
    "        print(f\"Successfully got GIS Item ID: {item_id}\")\n",
    "        return item\n",
    "\n",
    "\n",
    "def log_profile_info(gis):\n",
    "    '''\n",
    "    Output print statement that displays gis properties\n",
    "    '''\n",
    "    print(\"Successfully logged into '{}' via the user '{}'\".format(\n",
    "        gis.properties.portalHostname,\n",
    "        gis.properties.user.username))\n",
    "\n",
    "\n",
    "def process_edits(feature_layer, data_frame, operation, gis=None, batch_count=20000, matching_field=None, upsert_flag=False):\n",
    "    \"\"\"\n",
    "    Append data to a Push edits from SDF to hosted feature layer.\n",
    "    Args:\n",
    "        feature_layer ([type]): Target layer that data is appended to\n",
    "        data_frame ([type]): Source data that will be appended to target layer.\n",
    "        operation ([type]): [description] TODO\n",
    "        batch_count (int, optional): Maximum Number of records in dataframe that that can be in a\n",
    "                                        set to be appended to target layer. Defaults to 50000.\n",
    "    \"\"\"\n",
    "    print('Processing {} Events.....'.format(len(data_frame)))\n",
    "    print(f\"Running {operation.upper()} on Hosted Feature Layer {feature_layer.properties.name}\")\n",
    "\n",
    "    # Chunk dataframe into lists based on batch count.\n",
    "    update_sets = list(batch_it(data_frame, batch_count))\n",
    "\n",
    "    for edits in update_sets:\n",
    "        try:\n",
    "            if feature_layer.properties.type == 'Table':\n",
    "                append_to_table(edits, feature_layer, gis, matching_field, upsert_flag)\n",
    "            else:\n",
    "                append_to_layer(edits, feature_layer, gis, matching_field, upsert_flag)\n",
    "        except:\n",
    "            print(\"Unable to run %s on Hosted Feature Layer %s\", operation.upper(), feature_layer.properties.name)\n",
    "            print(\"Attempted to run %s on data %s\", operation.upper(), edits.spatial.to_featureset().features)\n",
    "\n",
    "            \n",
    "def query_layer(lyr, fields=None, geometry_flag=True, time_bound=False, geometry_filter_obj=None):\n",
    "    \"\"\"Return dataframe based on a layer query.\"\"\"\n",
    "    # Set time to record time spent running the query method from the python api.\n",
    "    start_time = time.time()\n",
    "\n",
    "    if geometry_filter_obj != None:\n",
    "        print(f\"Running a geometry based query on {lyr.properties.name}\")\n",
    "        df = geometry_based_query(lyr, geometry_filter_obj)\n",
    "    elif time_bound:\n",
    "        print(\"Running time bound query on {}\".format(lyr.properties.name))\n",
    "        clause = time_bound_clause(datetime_field, time_range)\n",
    "        df =  lyr.query(where=clause, return_geometry=geometry_flag, as_df=True)\n",
    "    else:\n",
    "        print(\"Running query on {}\".format(lyr.properties.name))\n",
    "        df =  lyr.query(return_geometry=geometry_flag, as_df=True)\n",
    "\n",
    "    print(f'Completed query of {lyr.properties.name} in {round((time.time() - start_time), 2)} seconds returning {len(df)} features')\n",
    "\n",
    "    # If geometry field is returned + a set of fields, append the geometry field name to the list.\n",
    "    if geometry_flag and fields is not None:\n",
    "        shape_field = df.select_dtypes('geometry').columns[0]\n",
    "        fields.append(shape_field)\n",
    "\n",
    "    # out_fields parameter in the query method does not work if date fields are restricted.\n",
    "    # Must run pandas filter method to restrict fields.\n",
    "    if fields is None:\n",
    "        return df\n",
    "    else:\n",
    "        return df[fields]\n",
    "    \n",
    "def reproject(in_df, out_sr):\n",
    "    \"\"\"\n",
    "    Reproject a dataframe to a new spatial reference.\n",
    "    :param in_df: Spatially enabled Dataframe - Required\n",
    "        Contains a shape field that contains a list of \n",
    "        ArcGIS Python API geometry objects.\n",
    "    :param out_sr: SpatialReference - Required\n",
    "        ArcGIS Python API SpatialReference object specifying the\n",
    "        desired output spatial reference.\n",
    "    :return Dataframe based on the input dataframe but in the new\n",
    "        spatial reference.\n",
    "    \"\"\"\n",
    "    # Ensure \"nan\" Does Not Appear in Aggregate Output Fields\n",
    "    [in_df[col].replace(np.nan, '', regex=True, inplace=True) for col in list(in_df.columns)]\n",
    "\n",
    "    # Convert dataframe into a featureset\n",
    "    feat_set = in_df.spatial.to_featureset()\n",
    "\n",
    "    # Extract the geometry from FeatureSet\n",
    "    in_geom_list = [f.geometry for f in feat_set]\n",
    "\n",
    "    # test to ensure the spatial reference is consistent across all the input geometries\n",
    "    in_wkid_lst = [geom['spatialReference']['wkid'] for geom in in_geom_list]\n",
    "    if len(set(in_wkid_lst)) > 1:\n",
    "        print('All spatial references in the input geometry list must be identical.')\n",
    "        raise Exception(\n",
    "            'All spatial references in the input geometry list must be identical.')\n",
    "\n",
    "    # set the input spatial reference based on the first spatial reference\n",
    "    in_sr = in_geom_list[0]['spatialReference']\n",
    "\n",
    "    # determine if a transformation needs to be applied\n",
    "    transformation_lst = find_transformation(in_sr, out_sr)['transformations']\n",
    "\n",
    "    # use the geometry service to reproject the geometry list using a transformation if needed\n",
    "    if len(transformation_lst):\n",
    "        out_geom_list = project(in_geom_list, in_sr,\n",
    "                                out_sr, transformation_lst[0])\n",
    "    else:\n",
    "        out_geom_list = project(in_geom_list, in_sr, out_sr)\n",
    "\n",
    "    # ensure the output geometries have the spatial reference explicitly defined\n",
    "    for geom in out_geom_list:\n",
    "        geom['spatialReference'] = out_sr\n",
    "\n",
    "    out_df = featureset_to_df(out_geom_list, feat_set)\n",
    "\n",
    "    print(\"Reprojection successful\")\n",
    "    return out_df\n",
    "    \n",
    "    \n",
    "def time_bound_clause(datetime_field: str, time_range: int) -> Text:\n",
    "    \"\"\"Create a where statement to look back at a specified time range in minutes. Time is converted to UTC\n",
    "\n",
    "    Args:\n",
    "        datetime_field (str): Field name from layer that is of the data type datetime.\n",
    "        time_range (int): Value in the unit of minutes.\n",
    "\n",
    "    Returns:\n",
    "        Text: A string formatted as a complete SQL clause. \n",
    "    \"\"\"\n",
    "    look_back_time = (datetime.utcnow() - timedelta(hours=0, minutes=time_range)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    where_clause = f\"{datetime_field} >= timestamp'{look_back_time}'\"\n",
    "\n",
    "    return where_clause"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0994ab1",
   "metadata": {},
   "source": [
    "### Enter Item ID Below of Source and Target Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8ee0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Layer details\n",
    "source_item_id = '59ea577aed334362bf7106c6771c82cf'\n",
    "soure_layer_id = 0\n",
    "\n",
    "# Target layer to load data into\n",
    "target_item_id = '59ea577aed334362bf7106c6771c82cf'\n",
    "target_layer_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6e3c2",
   "metadata": {},
   "source": [
    "### Grab the Layer content from source and target layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10482cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to retrieve layer with item id: 59ea577aed334362bf7106c6771c82cf\n",
      "Successfully got GIS Item ID: 59ea577aed334362bf7106c6771c82cf\n",
      "Running query on Geoenabled_Chats\n",
      "Completed query of Geoenabled_Chats in 0.89 seconds returning 449 features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "449"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_item = get_gis_item(target_item_id, gis)\n",
    "target_lyr = target_item.layers[0]\n",
    "target_df = query_layer(target_lyr)\n",
    "original_len = len(target_df)\n",
    "original_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ffe809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to retrieve layer with item id: 59ea577aed334362bf7106c6771c82cf\n",
      "Successfully got GIS Item ID: 59ea577aed334362bf7106c6771c82cf\n",
      "Running query on Geoenabled_Chats\n",
      "Completed query of Geoenabled_Chats in 0.77 seconds returning 449 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_id</th>\n",
       "      <th>created</th>\n",
       "      <th>extracted_entity</th>\n",
       "      <th>geocoded_lat</th>\n",
       "      <th>geocoded_long</th>\n",
       "      <th>geocoding_source</th>\n",
       "      <th>message_body</th>\n",
       "      <th>msg_parsed</th>\n",
       "      <th>username</th>\n",
       "      <th>ObjectId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Creator</th>\n",
       "      <th>EditDate</th>\n",
       "      <th>Editor</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63d977160c5d388d24867d7c</td>\n",
       "      <td>2023-01-31 20:16:22.739000082</td>\n",
       "      <td>12SVA8360167751</td>\n",
       "      <td>32.246</td>\n",
       "      <td>-111.174</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>man seen flying near airplane at 12SVA8360167751</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>{\"x\": -12375833.069451395, \"y\": 3795645.443935...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63d9772d0c5d388d24867d7e</td>\n",
       "      <td>2023-01-31 20:16:45.730999947</td>\n",
       "      <td>null</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>asdfsadfasdfsad</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63d977340c5d388d24867d80</td>\n",
       "      <td>2023-01-31 20:16:52.282999992</td>\n",
       "      <td>10SFJ3955214272</td>\n",
       "      <td>38.966</td>\n",
       "      <td>-121.389</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>16 tanks seen at 10SFJ3955214272</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>{\"x\": -13512961.667904684, \"y\": 4716802.533805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63d9773b0c5d388d24867d82</td>\n",
       "      <td>2023-01-31 20:16:59.154999971</td>\n",
       "      <td>13VFK4119422905</td>\n",
       "      <td>62.411</td>\n",
       "      <td>-102.267</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>Friendly fire, hold your fire 13VFK4119422905</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>{\"x\": -11384310.364955708, \"y\": 8957261.920682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63d977c20c5d388d24867d84</td>\n",
       "      <td>2023-01-31 20:19:14.186000109</td>\n",
       "      <td>09VVD4947855601</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>POI GRID 09VVD4947855601, Killbox 32AY3NE, MAX...</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       F_id                       created extracted_entity  \\\n",
       "0  63d977160c5d388d24867d7c 2023-01-31 20:16:22.739000082  12SVA8360167751   \n",
       "1  63d9772d0c5d388d24867d7e 2023-01-31 20:16:45.730999947             null   \n",
       "2  63d977340c5d388d24867d80 2023-01-31 20:16:52.282999992  10SFJ3955214272   \n",
       "3  63d9773b0c5d388d24867d82 2023-01-31 20:16:59.154999971  13VFK4119422905   \n",
       "4  63d977c20c5d388d24867d84 2023-01-31 20:19:14.186000109  09VVD4947855601   \n",
       "\n",
       "   geocoded_lat  geocoded_long geocoding_source  \\\n",
       "0        32.246       -111.174        GEOPARSER   \n",
       "1          <NA>           <NA>             <NA>   \n",
       "2        38.966       -121.389        GEOPARSER   \n",
       "3        62.411       -102.267        GEOPARSER   \n",
       "4          <NA>           <NA>        GEOPARSER   \n",
       "\n",
       "                                        message_body msg_parsed     username  \\\n",
       "0   man seen flying near airplane at 12SVA8360167751       true  topowright    \n",
       "1                                    asdfsadfasdfsad       true  topowright    \n",
       "2                   16 tanks seen at 10SFJ3955214272       true  topowright    \n",
       "3      Friendly fire, hold your fire 13VFK4119422905       true  topowright    \n",
       "4  POI GRID 09VVD4947855601, Killbox 32AY3NE, MAX...       true  topowright    \n",
       "\n",
       "   ObjectId                  CreationDate           Creator  \\\n",
       "0         1 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "1         2 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "2         3 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "3         4 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "4         5 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "\n",
       "                       EditDate            Editor  \\\n",
       "0 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "1 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "2 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "3 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "4 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "\n",
       "                                               SHAPE  \n",
       "0  {\"x\": -12375833.069451395, \"y\": 3795645.443935...  \n",
       "1                                               None  \n",
       "2  {\"x\": -13512961.667904684, \"y\": 4716802.533805...  \n",
       "3  {\"x\": -11384310.364955708, \"y\": 8957261.920682...  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_item = get_gis_item(source_item_id, gis)\n",
    "source_lyr = source_item.layers[0]\n",
    "source_df = query_layer(source_lyr)\n",
    "source_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa12f8",
   "metadata": {},
   "source": [
    "### Add data to target layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45c0d4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features being added: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_id</th>\n",
       "      <th>created</th>\n",
       "      <th>extracted_entity</th>\n",
       "      <th>geocoded_lat</th>\n",
       "      <th>geocoded_long</th>\n",
       "      <th>geocoding_source</th>\n",
       "      <th>message_body</th>\n",
       "      <th>msg_parsed</th>\n",
       "      <th>username</th>\n",
       "      <th>ObjectId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Creator</th>\n",
       "      <th>EditDate</th>\n",
       "      <th>Editor</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63d977160c5d388d24867d7c</td>\n",
       "      <td>2023-01-31 20:16:22.739000082</td>\n",
       "      <td>12SVA8360167751</td>\n",
       "      <td>32.246</td>\n",
       "      <td>-111.174</td>\n",
       "      <td>GEOPARSER</td>\n",
       "      <td>man seen flying near airplane at 12SVA8360167751</td>\n",
       "      <td>true</td>\n",
       "      <td>topowright</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>2023-06-30 16:35:46.644000053</td>\n",
       "      <td>foretify_rbeitel</td>\n",
       "      <td>{\"x\": -12375833.069451395, \"y\": 3795645.443935...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       F_id                       created extracted_entity  \\\n",
       "0  63d977160c5d388d24867d7c 2023-01-31 20:16:22.739000082  12SVA8360167751   \n",
       "\n",
       "   geocoded_lat  geocoded_long geocoding_source  \\\n",
       "0        32.246       -111.174        GEOPARSER   \n",
       "\n",
       "                                       message_body msg_parsed     username  \\\n",
       "0  man seen flying near airplane at 12SVA8360167751       true  topowright    \n",
       "\n",
       "   ObjectId                  CreationDate           Creator  \\\n",
       "0         1 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "\n",
       "                       EditDate            Editor  \\\n",
       "0 2023-06-30 16:35:46.644000053  foretify_rbeitel   \n",
       "\n",
       "                                               SHAPE  \n",
       "0  {\"x\": -12375833.069451395, \"y\": 3795645.443935...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = source_df.iloc[0:1]\n",
    "features_added = len(tmp_df)\n",
    "print(f'Number of features being added: {features_added}')\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb7500d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 Events.....\n",
      "Running ADD on Hosted Feature Layer Geoenabled_Chats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\GitHub\\UsefulPython\\update_feature_service\\.venv\\lib\\site-packages\\arcgis\\features\\geo\\_accessor.py:3450: UserWarning: Discarding nonzero nanoseconds in conversion.\n",
      "  row[f] = int(row[f].to_pydatetime().timestamp() * 1000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to append records in d6edc96bb3094f97a97dbe818c96ff18 on Hosted Feature Layer Geoenabled_Chats\n",
      "Unable to append on Hosted Feature Layer Geoenabled_Chats\n",
      "Unable to run %s on Hosted Feature Layer %s ADD Geoenabled_Chats\n",
      "Attempted to run %s on data %s ADD [{\"geometry\": {\"x\": -12375833.069451395, \"y\": 3795645.443935541, \"spatialReference\": {\"wkid\": 102100, \"latestWkid\": 3857}}, \"attributes\": {\"F_id\": \"63d977160c5d388d24867d7c\", \"created\": 1675224982739, \"extracted_entity\": \"12SVA8360167751\", \"geocoded_lat\": 32.246, \"geocoded_long\": -111.174, \"geocoding_source\": \"GEOPARSER\", \"message_body\": \"man seen flying near airplane at 12SVA8360167751\", \"msg_parsed\": \"true\", \"username\": \"topowright \", \"ObjectId\": 1, \"CreationDate\": 1688168146644, \"Creator\": \"foretify_rbeitel\", \"EditDate\": 1688168146644, \"Editor\": \"foretify_rbeitel\"}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\GitHub\\UsefulPython\\update_feature_service\\.venv\\lib\\site-packages\\arcgis\\features\\geo\\_accessor.py:3450: UserWarning: Discarding nonzero nanoseconds in conversion.\n",
      "  row[f] = int(row[f].to_pydatetime().timestamp() * 1000)\n"
     ]
    }
   ],
   "source": [
    "process_edits(target_lyr, tmp_df, 'add', gis=gis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b51f31c",
   "metadata": {},
   "source": [
    "### Validate that features have been successfully added to the target layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull source layer into a dataframe again\n",
    "target_item = get_gis_item(target_item_id, gis)\n",
    "target_lyr = target_item.layers[0]\n",
    "target_df = query_layer(target_lyr)\n",
    "updated_len = len(target_df)\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7b880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "242a50fb",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b63972fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original number of features in the target layer is: 449\n",
      "The number of features being added to the target layer is: 1\n",
      "The expected length of the updated target feature service is: 450\n"
     ]
    }
   ],
   "source": [
    "print(f\"The original number of features in the target layer is: {original_len}\")\n",
    "print(f\"The number of features being added to the target layer is: {features_added}\")\n",
    "print(f\"The expected length of the updated target feature service is: {original_len + features_added}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if updated_len == original_len + features_added:\n",
    "    print(f\"The number of features in the target layer is as expected: {updated_len}\")\n",
    "else:\n",
    "    print(f\"The number of features in the target layer is NOT as expected: {updated_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106ac72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47700dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ab6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5739e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640bf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563cdd5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3da48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebff4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cbee2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852420b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fafbc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2a1b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b27663f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2312c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
